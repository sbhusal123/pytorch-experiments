{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd550bf3-43ad-4ae8-a7df-4707364f43cf",
   "metadata": {},
   "source": [
    "# Neural Networks Vs Linear Models:\n",
    "\n",
    "## 1. Linear Models Vs Neural Networks:\n",
    "\n",
    "Linear models captures the linear relationship in a given dataset.\n",
    "\n",
    "Linear models cannot solve many machine learning problems effectively. Even if we combine them into a **composite function**\n",
    "$f_2(f_1(x))$, a composite function of linear functions remains linear. This is straightforward to verify.\n",
    "\n",
    "Let's define $y_1=f_1(x)=a_1x$ and $y_2=f_1(x)=a_2x$, here $f_2$ depends on $f_1$ making it composite function. We can write $f_2$ as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b475653d-6ac1-4ecb-8eaa-8942dc0e95f7",
   "metadata": {},
   "source": [
    "$y_2=a_2y1=a_2(a_1x)=a_2a_1x$\n",
    "\n",
    "Since $a_2, a_1$ are constants, suppose $a_3=a_2a_1$ thus $y_2=a_3x$ which is can only capture the linear relation. \n",
    "To address this issue, we add non-linearity. For one dimensional input\n",
    "\n",
    "$y=\\phi(wx+b)$$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd404cf-45c9-4166-87aa-865430774a9f",
   "metadata": {},
   "source": [
    "The function $\\phi$ is a fixed non-linear function, known as activation function. Common choices are:\n",
    "\n",
    "## 2. Activation Functions\n",
    "\n",
    "### i. RELU (Rectified Linear Unit):\n",
    "\n",
    "$$RELU(z)=max(0,z)$$\n",
    "\n",
    "**outputs non negative values.**\n",
    " \n",
    "### ii. Sigmoid: \n",
    "\n",
    "$$\\sigma(x)=\\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "**Outputs values between 0 and 1, making it suitable for binary classification.**\n",
    "\n",
    "### iii. Tanh(hyperbolic tangent)\n",
    "\n",
    "$$tanh=\\frac{e^{z}-e^{-z}}{e^{z}+e^{-z}}$$\n",
    "\n",
    "**Outputs value in between 1 and -1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309ef3a7-152f-4782-b8ab-f76eab2de68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def relu(z):\n",
    "    return np.maximum(z, 0)\n",
    "\n",
    "def sigmoid(z):\n",
    "    den = 1 + np.exp(-z)\n",
    "    return 1/den\n",
    "\n",
    "def tanh(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "x = np.linspace(-5,5,40000)\n",
    "\n",
    "relu_vect = np.vectorize(relu)\n",
    "sigmoid_vect = np.vectorize(sigmoid)\n",
    "tanh_vect = np.vectorize(tanh)\n",
    "\n",
    "y_relu = relu_vect(x)\n",
    "y_sigmoid = sigmoid_vect(x)\n",
    "y_tanh = tanh_vect(x)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y_relu, label=\"ReLU\", linewidth=2)\n",
    "plt.plot(x, y_sigmoid, label=\"Sigmoid\", linewidth=2)\n",
    "plt.plot(x, y_tanh, label=\"Tanh\", linewidth=2)\n",
    "\n",
    "plt.title(\"Activation Functions\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.grid(True)\n",
    "plt.axhline(0, color=\"black\", linewidth=0.5)\n",
    "plt.axvline(0, color=\"black\", linewidth=0.5)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc20cd7-a2c1-407a-9c24-95a847c692c8",
   "metadata": {},
   "source": [
    "Structure $\\phi(wx+b)$ enables learning non-linear models but cannot capture all non-linear curves. By nesting these functions,\n",
    "we build more expressive models. \n",
    "\n",
    "**Suppose:**\n",
    "\n",
    "$$f_1(x)=\\phi(ax+b)$$\n",
    "$$f_2(z)=\\phi(cz+d)$$\n",
    "\n",
    "Then,\n",
    "\n",
    "$$y=f_2(f_1(x)) = \\phi(c \\phi(ax+b)+d)$$\n",
    "\n",
    "Figure below shows the computational graph of the composite two functions.\n",
    "\n",
    "![Graph](./images/graph.png)\n",
    "\n",
    "Below below shows computational graph with 2d input and 2 layers.\n",
    "![Graph](./images/multi-layer-computational-graph.png)\n",
    "\n",
    "## 3. Loss Function Optimization With Gradient Descent:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d868ec02-0b01-49c2-8535-14e65d2fb7e7",
   "metadata": {},
   "source": [
    "Gradient descent algorithm is widely used to minimize the\n",
    "loss, including in large language models. \n",
    "\n",
    "## Consider:\n",
    "    \n",
    "Binary classification problem\n",
    "\n",
    "Training Dataset: $D$ is $\\{(x_i, y_i)\\}_{i=1}^{N}$, here:\n",
    "- $x_i$ is training dataset feature\n",
    "- $y_i$ indexed from 1 to N, takes 0 or 1\n",
    "\n",
    "To train a model on these classification problem we can define:\n",
    "\n",
    "$$y=\\sigma(w.x+b)$$\n",
    "\n",
    "Where, $\\mathbf{x} = \\left[ x^{(j)} \\right]_{j=1}^{D}$ and $\\mathbf{w} = \\left[ w^{(j)} \\right]_{j=1}^{D}$ are D dimensional vector. This model is called **Logistic Regression** commonly used for binary classification problem.\n",
    "\n",
    "Common choice of function for logistic regression is:\n",
    "\n",
    "$$\\text{loss}(\\tilde{y}_i, y_i) \\overset{\\text{def}}{=} -\\left[ y_i \\log(\\tilde{y}_i) + (1 - y_i)\\log(1 - \\tilde{y}_i) \\right]$$\n",
    "\n",
    "Its value takes from $- \\infty, \\infty$ logistic regression always outputs values between 0 and 1. It can serve **either as a standalone model or as the output layer in a larger neural network.**\n",
    "\n",
    "Loss functions are usually designed to penalize incorrect predictions while re-\n",
    "warding accurate ones. To see why logistic loss works for logistic regression,\n",
    "consider two extreme cases:\n",
    "\n",
    "**1.Perfect Prediction:** When, $y_i=0,\\tilde{y}=0$\n",
    "Then, $$loss(0,0)=[-0.log(0)+(1-0).log(1-0)]=-log(1)=0$$\n",
    "\n",
    "Here, loss is zero which because prediction matches label.\n",
    "\n",
    "**2.Opposite Prediction:** When, $y_i=0,\\tilde{y}=1$\n",
    "\n",
    "Then, $$loss(1,0)=[-0.log(1)+(1-0).log(1-1)]=-log(0)=-\\infty$$\n",
    "\n",
    "For entire dataset D, \n",
    "\n",
    "$$loss_{D}=\\frac{1}{N} \\sum_{i = 1}^{N} [y_i log(\\tilde{y}) + (1-y_i) log(1- \\tilde{y}) ] $$\n",
    "\n",
    "To simplify this to calculate the gradient descent derivatives:\n",
    "\n",
    "$$loss(\\tilde{y}_i, y_i) = - [ y_i log(\\sigma(z_i)) + (1-y_i) log((1-\\sigma(z_i)) ]$$\n",
    "\n",
    "\n",
    "To minimize, $loss(\\tilde{y}_i, y_i)$, we calculate the **partial derivatives with respect to each weights: $w^j$ and b**\n",
    "\n",
    "We can use chain rule because we have composite function as belows:\n",
    "\n",
    "- **Function 1:** $z_i=wx+b$, a linear function with weight **w** and bias **b**\n",
    "\n",
    "- **Function 2:** $\\tilde{y} = \\sigma(z_i) = \\frac{1}{1+e^{-z_i}}$, sigmoid applied to $z_i$\n",
    "\n",
    "- **Function 2** $loss(\\tilde y_i,y_i)$ as defined in above equation\n",
    "\n",
    "**Suppose,** $loss( \\tilde y_i, y_i) = l_i$. For weights $w^{(j)}$ , the application of chain rule gives us.\n",
    "\n",
    "\n",
    "The linear combination:\n",
    "$$z_i = w x_i + b$$\n",
    "\n",
    "The sigmoid activation function:\n",
    "$$\\hat{y}_i = \\sigma(z_i) = \\frac{1}{1 + e^{-z_i}}$$\n",
    "\n",
    "The binary cross-entropy loss function:\n",
    "$$\\text{Loss}(\\hat{y}_i, y_i) = -[y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)]$$\n",
    "\n",
    "\n",
    "$$\\frac{\\partial L_i}{\\partial w_i} = \\frac{\\partial L_i}{\\partial \\hat{y}_i} \\cdot \\frac{\\partial \\hat{y}_i}{\\partial z_i} \\cdot \\frac{\\partial z_i}{\\partial w_i}$$\n",
    "\n",
    "## 1. Calculating $ \\frac { \\partial l_i} { \\partial w^{(j)} } $\n",
    "\n",
    "Let's calculate each term:\n",
    "\n",
    "**i. Calculate $\\frac{\\partial L_i}{\\partial \\hat{y}_i}$:**\n",
    "\n",
    "$$\\frac{\\partial L_i}{\\partial \\hat{y}_i} = \\frac{\\partial}{\\partial \\hat{y}_i} \\left( -[y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)] \\right)$$$$\\frac{\\partial L_i}{\\partial \\hat{y}_i} = -\\left[ y_i \\cdot \\frac{1}{\\hat{y}_i} + (1 - y_i) \\cdot \\frac{-1}{1 - \\hat{y}_i} \\right]$$$$\\frac{\\partial L_i}{\\partial \\hat{y}_i} = -\\left[ \\frac{y_i}{\\hat{y}_i} - \\frac{1 - y_i}{1 - \\hat{y}_i} \\right]$$\n",
    "\n",
    "$$\\frac{\\partial L_i}{\\partial \\hat{y}_i} = \\frac{1 - y_i}{1 - \\hat{y}_i} - \\frac{y_i}{\\hat{y}_i}$$\n",
    "\n",
    "**ii. Calculate $\\frac{\\partial \\hat{y}_i}{\\partial z_i}$:**\n",
    "\n",
    "\n",
    "$$ \\frac {\\partial \\tilde y_i} { \\partial z _i} = \\frac { \\partial } {\\partial z_i} (\\frac {1} {1 + e ^{ -z_i}} )$$\n",
    "\n",
    "Let, $1 + e ^ {-z_i} = u$ thus,\n",
    "\n",
    "$$ \\frac {1} {1 + e^{-z_i}} = \\frac {1} {u}$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$ \\frac { \\partial \\tilde y_i} { \\partial z_i} = \\frac {\\partial} {\\partial u} (\\frac {1} {u}) . \\frac { \\partial u } { \\partial z } $$\n",
    "\n",
    "$$= \\frac { \\partial } { \\partial u } ( u ^ {-1} ) . \\frac { \\partial u} { \\partial z } $$\n",
    "\n",
    "$$ = ( - u ^ {-2} ) . \\frac { \\partial } { \\partial z } ( 1 + e ^ {-z_i}) $$\n",
    "\n",
    "$$ = \\frac {-1} { (1 + e ^ {-z_i})^{2}  } . (- e ^ { -z_i }) $$\n",
    "\n",
    "$$ = \\frac { e ^ {-z_i} } { (1 + e^{-z_i})^{2} } $$\n",
    "\n",
    "Let's multiply numerator and denominator by $e^z_i$\n",
    "\n",
    "$$ \\frac{\\partial \\hat{y}_i}{\\partial z_i} = \\frac { e ^ {-z_i} . e ^ {z_i}  } { (1 + e^{-z_i})^{2} . e ^ {z_i}} $$\n",
    "\n",
    "$$ = \\frac { e ^ {-z_i}  } { (1 + e^{-z_i})} .  \\frac {1} {1 + e^{-z_i}} $$\n",
    "\n",
    "**Here,**\n",
    "\n",
    "$$ 1 - \\tilde y_i = \\frac { e^{-z_i} } {1 + e^{-z_i} } $$\n",
    "\n",
    "**Thus,**\n",
    "\n",
    "$$ \\frac{\\partial \\hat{y}_i}{\\partial z_i} = \\tilde y_i (1 - \\tilde y_i) $$\n",
    "\n",
    "\n",
    "**iii. Calculate $\\frac{\\partial z_i}{\\partial w_i}$:**\n",
    "\n",
    "$$\\frac{\\partial z_i}{\\partial w_i} = \\frac{\\partial}{\\partial w_i} (w x_i + b)$$\n",
    "$$\\frac{\\partial z_i}{\\partial w_i} = x_i $$\n",
    "\n",
    "\n",
    "**Thus we have:**\n",
    "\n",
    "$$\\frac{\\partial L_i}{\\partial \\hat{y}_i} = \\frac{1 - y_i}{1 - \\hat{y}_i} - \\frac{y_i}{\\hat{y}_i}$$\n",
    "\n",
    "$$ \\frac{\\partial \\hat{y}_i}{\\partial z_i} = \\tilde y_i (1 - \\tilde y_i) $$\n",
    "\n",
    "$$\\frac{\\partial z_i}{\\partial w_i} = x_i $$\n",
    "\n",
    "$$ \\frac{\\partial L_i}{\\partial w^j} =   \\frac{\\partial L_i}{\\partial \\hat{y}_i} \\cdot \\frac{\\partial \\hat{y}_i}{\\partial z_i} \\cdot \\frac{\\partial z_i}{\\partial w_i} = ( \\frac{1 - y_i}{1 - \\hat{y}_i} - \\frac{y_i}{\\hat{y}_i} ) .  ( \\tilde y_i (1 - \\tilde y_i) ) . ( x_i ) = ( \\tilde y_i - y_i ) x_i $$\n",
    "\n",
    "$$ \\frac{\\partial L_i}{\\partial w^j} =  ( \\tilde y_i - y_i ) x_i $$ \n",
    "\n",
    "## 1. Calculating $ \\frac { \\partial l_i} { \\partial b } $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5c2ca-5613-4d06-9bfb-1f8cbd4fe787",
   "metadata": {},
   "source": [
    "**Using Chain Rule:**\n",
    "\n",
    "$$ \\frac { \\partial l_i} { \\partial b } = \\frac { \\partial l_i} { \\partial \\tilde y_i } .\n",
    "\\frac { \\partial \\tilde y_i } { \\partial z_i } . \\frac { \\partial z_i } { \\partial b }\n",
    "$$\n",
    "\n",
    "**We Have:**\n",
    "\n",
    "$$\\frac{\\partial l_i}{\\partial \\hat{y}_i} = \\frac{1 - y_i}{1 - \\hat{y}_i} - \\frac{y_i}{\\hat{y}_i}$$\n",
    "\n",
    "$$ \\frac{\\partial \\hat{y}_i}{\\partial z_i} = \\tilde y_i (1 - \\tilde y_i) $$\n",
    "\n",
    "**To calculate $ \\frac { \\partial z_i } { \\partial b } $**\n",
    "\n",
    "$$\\frac { \\partial z_i } { \\partial b } = \\frac { \\partial } { \\partial b } ( wx+b ) = 1 $$\n",
    "\n",
    "**Thus**\n",
    "\n",
    "\n",
    "$$ \n",
    "\\frac { \\partial l_i} { \\partial b } = \\frac { \\partial l_i} { \\partial \\tilde y_i } .\n",
    "\\frac { \\partial \\tilde y_i } { \\partial z_i } . \\frac { \\partial z_i } { \\partial b }\n",
    "= ( \\frac{1 - y_i}{1 - \\hat{y}_i} - \\frac{y_i}{\\hat{y}_i} ) . (  \\tilde y_i (1 - \\tilde y_i) ) . 1\n",
    "= \\tilde y_i - y_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3a63b7-f502-4752-af4e-33d325f09bdb",
   "metadata": {},
   "source": [
    "## Parameter Update Rule:\n",
    "\n",
    "The partial derivatives with respect to $w^{(j)}$ and $b$ for a single example $(x_i, y_i)$ can be extended to the entire dataset $\\{(x_i, y_i)\\}_{i=1}^{N}$ by averaging the contributions from all examples.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{loss}}{\\partial w^{(j)}} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[ (\\hat{y}_i - y_i) \\cdot x_i^{(j)} \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\text{loss}}{\\partial b} = \\frac{1}{N} \\sum_{i=1}^{N} \\left[ \\hat{y}_i - y_i \\right]\n",
    "$$\n",
    "\n",
    "Here, loss denotes the average loss for the entire dataset. Averaging the losses for individual examples ensures that each example contributes equally to the overall loss, regardless of the total number of examples.\n",
    "\n",
    "The **gradient** is a vector that contains all the partial derivatives. The gradient of the loss function, denoted as $\\nabla \\text{loss}$, is defined as follows:\n",
    "\n",
    "$$\n",
    "\\nabla \\text{loss} \\stackrel{\\text{def}}{=} \\left( \\frac{\\partial \\text{loss}}{\\partial w^{(1)}}, \\frac{\\partial \\text{loss}}{\\partial w^{(2)}}, \\cdots, \\frac{\\partial \\text{loss}}{\\partial w^{(D)}}, \\frac{\\partial \\text{loss}}{\\partial b} \\right)\n",
    "$$\n",
    "\n",
    "If a gradient's component is positive, this means that increasing the corresponding parameter will increase the loss. **Therefore, to minimize the loss, we should decrease that parameter as below:**\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "w^{(j)} \\leftarrow w^{(j)} - \\eta \\frac{\\partial \\text{loss}}{\\partial w^{(j)}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b \\leftarrow b - \\eta \\frac{\\partial \\text{loss}}{\\partial b}\n",
    "$$\n",
    "\n",
    "**Here, $\\eta$ is a learning rate. Ah, the learning rate! It's a hyperparameter in machine learning and optimization algorithms that determines the step size at each iteration while moving toward a minimum of a loss function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6a25b-4fc0-4abb-8695-40c85ac0f2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
